{
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "",
  "signature": "sha256:1f594cb7e5de420ee4f17502a909927f132ed80443eeb01c2e23cab9075dd1cd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Sentiment Analysis\n",
      "\n",
      "#### Note that this process works for any type of labeling - it could be used for topics, emotions, etc.. May be worth looking into\n",
      "\n",
      "First manually label what information we want extracted, try to make sure there are hundreds of cases\n",
      "The code below will create a model. This model can be retrained with more observations or saved. Once the model is created, test data or new data can be used to score and export for use. The latter part is not in this code as of v1.0"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv('trainData.csv')\n",
      "\n",
      "##Removed data for privacy concerns        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "File trainData.csv does not exist",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-a8f169922a1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'trainData.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, na_fvalues, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[0;32m    472\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 474\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    475\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 705\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    706\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    707\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\io\\parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1070\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1072\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1073\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\parser.pyd\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas\\parser.c:3173)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;32mC:\\Users\\jswortz\\AppData\\Local\\Enthought\\Canopy\\User\\lib\\site-packages\\pandas\\parser.pyd\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas\\parser.c:5912)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: File trainData.csv does not exist"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## From http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
      "\n",
      "Tokenizing text with scikit-learn\u00b6\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cross_validation import train_test_split\n",
      "vectorizer = CountVectorizer(ngram_range = (1,4), stop_words='english')\n",
      "\n",
      "train, test = train_test_split(data, test_size = 0.3)\n",
      "\n",
      "x = vectorizer.fit_transform(train.feedback)\n",
      "x.shape\n",
      "#note that shape gives you the number of documents in training by the number of features"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 98,
       "text": [
        "(561, 37633)"
       ]
      }
     ],
     "prompt_number": 98
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "tf_transformer = TfidfTransformer(use_idf=False).fit(x)\n",
      "X_train_tf = tf_transformer.transform(x)\n",
      "print X_train_tf.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(561, 37633)\n"
       ]
      }
     ],
     "prompt_number": 99
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training a classifier\n",
      "\n",
      "Now that we have our features, we can train a classifier to try to predict the category of a post. Let\u2019s start with a na\u00efve Bayes classifier, which provides a nice baseline for this task. scikit-learn includes several variants of this classifier; the one most suitable for word counts is the multinomial variant:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "\n",
      "clf = MultinomialNB().fit(X_train_tf, train.Label)\n",
      "\n",
      "xTest = vectorizer.transform(test['feedback'])\n",
      "X_train_tfTest = tf_transformer.transform(xTest)\n",
      "\n",
      "print X_train_tfTest.shape\n",
      "predicted = clf.predict(X_train_tfTest)\n",
      "\n",
      "print zip(predicted, test.Label)\n",
      "import numpy as np\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "#roc = roc_auc_score(test.Label, predicted)\n",
      "## this is commented out since AUC is supported for binary classes\n",
      "#print \"Area under the ROC curve: %.4f\" % (roc)\n",
      "prf = precision_recall_fscore_support(test.Label, predicted, average = 'micro')\n",
      "print \"Precision : %.4f  Recall : %.4f  F-Score : %.4f\" % (prf[0], prf[1], prf[2])\n",
      "accuracy = np.mean(test.Label == predicted)\n",
      "print \"Accuracy : %.4f\" % (accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(241, 37633)\n",
        "[(-1, -1), (1, 1), (-1, 0), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (-1, 0), (-1, -1), (-1, -1), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (1, 0), (1, 1), (-1, -1), (1, 1), (-1, 0), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, -1), (-1, -1), (1, 0), (-1, 0), (-1, 0), (-1, -1), (1, 0), (1, 1), (1, 1), (1, 1), (-1, -1), (-1, 0), (-1, -1), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (1, -1), (1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (-1, 0), (-1, 0), (-1, -1), (1, 1), (-1, -1), (1, -1), (-1, -1), (-1, -1), (1, -1), (1, -1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 0), (-1, -1), (1, 1), (1, 1), (-1, -1), (-1, 0), (-1, 0), (-1, 0), (-1, 0), (-1, -1), (-1, 1), (1, 1), (-1, -1), (1, 1), (-1, 0), (1, 0), (1, -1), (-1, -1), (1, 0), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 0), (-1, -1), (-1, -1), (1, 0), (-1, 0), (1, 1), (1, 1), (-1, -1), (1, 0), (1, 0), (1, 1), (1, -1), (-1, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (-1, 1), (1, 0), (1, 1), (-1, 0), (-1, -1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, 0), (1, 1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (-1, 0), (1, 0), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, 0), (-1, -1), (-1, 0), (1, 1), (-1, -1), (-1, 1), (-1, 0), (1, 0), (-1, 0), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, -1), (1, 1), (1, -1), (-1, -1), (-1, 0), (1, 1), (-1, -1), (-1, -1), (1, 1), (-1, 0), (-1, 0), (-1, -1), (1, 1), (1, 1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 0), (1, 1), (-1, 0), (1, 0), (-1, -1), (1, -1), (1, 0), (-1, 1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (-1, 0), (1, 1), (-1, 0), (1, 0), (-1, -1), (1, 1), (1, 1), (-1, 1), (1, 1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, -1), (1, -1), (1, 1), (-1, -1), (1, 1), (1, 1), (-1, 0)]\n",
        "Precision : 0.7178  Recall : 0.7178  F-Score : 0.7178\n",
        "Accuracy : 0.7178\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "SVM Evaluation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "\n",
      "clf2 = SGDClassifier(loss='hinge', penalty='elasticnet', class_weight  = 'balanced', \n",
      "                     alpha=1e-3,l1_ratio = 0, n_iter=400, random_state=42).fit(X_train_tf, train.Label)\n",
      "predicted = clf2.predict(X_train_tfTest)\n",
      "\n",
      "print zip(predicted, test.Label)\n",
      "import numpy as np\n",
      "from sklearn.metrics import roc_auc_score\n",
      "from sklearn.metrics import precision_recall_fscore_support\n",
      "#roc = roc_auc_score(test.Label, predicted)\n",
      "#print \"Area under the ROC curve: %.4f\" % (roc)\n",
      "prf = precision_recall_fscore_support(test.Label, predicted, average = 'micro')\n",
      "print \"Precision : %.4f  Recall : %.4f  F-Score : %.4f\" % (prf[0], prf[1], prf[2])\n",
      "accuracy = np.mean(test.Label == predicted)\n",
      "print \"Accuracy : %.4f\" % (accuracy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[(0, -1), (1, 1), (-1, 0), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 1), (1, 1), (0, -1), (-1, -1), (-1, -1), (-1, 0), (-1, -1), (-1, -1), (1, 0), (1, 1), (1, 1), (1, 0), (1, 1), (-1, 0), (1, 1), (-1, -1), (1, 1), (-1, 0), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, -1), (-1, -1), (1, 0), (-1, 0), (-1, 0), (-1, -1), (1, 0), (1, 1), (0, 1), (1, 1), (-1, -1), (-1, 0), (-1, -1), (-1, -1), (1, 1), (1, 1), (1, 1), (1, -1), (1, 1), (1, 1), (1, 1), (0, -1), (1, 0), (1, 1), (-1, -1), (1, -1), (-1, 1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (-1, -1), (0, -1), (1, 1), (-1, -1), (0, 0), (-1, 0), (-1, -1), (1, 1), (-1, -1), (1, -1), (-1, -1), (-1, -1), (1, -1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 0), (-1, -1), (1, 1), (1, 1), (-1, -1), (0, 0), (-1, 0), (-1, 0), (0, 0), (-1, -1), (0, 1), (1, 1), (-1, -1), (1, 1), (-1, 0), (1, 0), (1, -1), (-1, -1), (1, 0), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, 0), (-1, -1), (-1, -1), (1, 0), (0, 0), (1, 1), (1, 1), (-1, -1), (1, 0), (1, 0), (1, 1), (1, -1), (0, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 0), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (-1, 1), (1, 0), (1, 1), (-1, 0), (-1, -1), (1, 1), (0, -1), (-1, -1), (-1, -1), (1, 1), (0, 0), (1, 1), (1, -1), (0, -1), (0, -1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (0, 0), (-1, 0), (1, 1), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, 0), (-1, -1), (-1, 0), (1, 1), (-1, -1), (-1, 1), (0, 0), (1, 0), (-1, 0), (-1, -1), (1, 1), (1, 1), (1, 1), (-1, -1), (1, 1), (1, -1), (-1, -1), (-1, 0), (1, 1), (-1, -1), (-1, -1), (1, 1), (0, 0), (-1, 0), (-1, -1), (1, 1), (1, 1), (0, -1), (0, -1), (1, 1), (-1, -1), (0, -1), (-1, -1), (-1, -1), (1, 1), (-1, -1), (1, 1), (-1, 0), (1, 1), (-1, 0), (1, 0), (-1, -1), (1, -1), (0, 0), (-1, 1), (1, 1), (-1, -1), (-1, -1), (-1, -1), (1, 1), (1, 1), (-1, -1), (-1, 0), (1, 1), (-1, 0), (1, 0), (-1, -1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1), (-1, -1), (1, 1), (-1, -1), (1, -1), (1, -1), (-1, 1), (-1, -1), (1, 1), (1, 1), (1, 0)]\n",
        "Precision : 0.7054  Recall : 0.7054  F-Score : 0.7054\n",
        "Accuracy : 0.7054\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Further performance reports and confusion matrix\n",
      "### if you were interested, a parameter grid search could be performed to optimize. This is the last exercise"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "def labeler(x):\n",
      "    if x == -1:\n",
      "        return 'negative'\n",
      "    elif x == 0:\n",
      "        return 'neutral'\n",
      "    else:\n",
      "        return 'positvie'\n",
      "test['desc'] = test['Label'].map(labeler)\n",
      "\n",
      "print(metrics.classification_report(test.Label, predicted, target_names = ['neg','neu','pos']))\n",
      "metrics.confusion_matrix(test.Label, predicted)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.72      0.77      0.74        98\n",
        "        neu       0.41      0.18      0.25        49\n",
        "        pos       0.75      0.91      0.82        94\n",
        "\n",
        "avg / total       0.67      0.71      0.67       241\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 161,
       "text": [
        "array([[75, 11, 12],\n",
        "       [23,  9, 17],\n",
        "       [ 6,  2, 86]])"
       ]
      }
     ],
     "prompt_number": 161
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Now with pipelines!\n",
      "## this method will pickle a classification pipeline to classify any new text\n",
      "# This is an All-In-One code for sentiment Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline\n",
      "import pickle\n",
      "from sklearn import metrics\n",
      "from sklearn.linear_model import SGDClassifier\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.feature_extraction.text import TfidfTransformer\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.cross_validation import train_test_split\n",
      "import os\n",
      "import pandas as pd\n",
      "\n",
      "data = pd.read_csv('trainData.csv')\n",
      "\n",
      "train, test = train_test_split(data, test_size = 0.1)\n",
      "\n",
      "\n",
      "text_clf = Pipeline([('vect', CountVectorizer(ngram_range = (1,4), stop_words='english')),\n",
      "                     ('tfidf', TfidfTransformer()),\n",
      "                     ('clf',SGDClassifier(loss='hinge', penalty='elasticnet', class_weight  = 'balanced', \n",
      "                     alpha=1e-3,l1_ratio = 0, n_iter=400, random_state=42))\n",
      "                    ])\n",
      "text_clf = text_clf.fit(train.feedback, train.Label)\n",
      "\n",
      "# with open('sentiment.pkl', 'wb') as f:\n",
      "#     pickle.dump(text_clf, f)\n",
      "\n",
      "predicted = text_clf.predict(test.feedback)\n",
      "\n",
      "print(metrics.classification_report(test.Label, predicted, target_names = ['neg','neu','pos']))\n",
      "prf = precision_recall_fscore_support(test.Label, predicted, average = 'micro')\n",
      "print \"Precision : %.4f  Recall : %.4f  F-Score : %.4f\" % (prf[0], prf[1], prf[2])\n",
      "accuracy = np.mean(test.Label == predicted)\n",
      "print \"Accuracy : %.4f\" % (accuracy)\n",
      "print \"\\n Confusion Matrix\"\n",
      "print(\"TOP: Predicted, SIDE: Actuals\")\n",
      "print(metrics.confusion_matrix(test.Label, predicted))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "        neg       0.60      0.90      0.72        30\n",
        "        neu       0.50      0.11      0.17        19\n",
        "        pos       0.88      0.88      0.88        32\n",
        "\n",
        "avg / total       0.69      0.70      0.65        81\n",
        "\n",
        "Precision : 0.7037  Recall : 0.7037  F-Score : 0.7037\n",
        "Accuracy : 0.7037\n",
        "\n",
        " Confusion Matrix\n",
        "TOP: Predicted, SIDE: Actuals\n",
        "[[27  1  2]\n",
        " [15  2  2]\n",
        " [ 3  1 28]]\n"
       ]
      }
     ],
     "prompt_number": 180
    }
   ],
   "metadata": {}
  }
 ]
}